#!/bin/bash
# ---------------------------------------------------------------- #
#                                                                  #
#  Example job submission script for Exabyte.io platform           #
#                                                                  #
#  Shows resource manager directives for:                          #
#                                                                  #
#    1. the name of the job                (-N)                    #
#    2. the number of nodes to be used     (-l nodes=)             #
#    3. the number of processors per node  (-l ppn=)               #
#    4. the walltime in dd:hh:mm:ss format (-l walltime=)          #
#    5. queue                              (-q) D, OR, OF, SR, SF  #
#    6. merging standard output and error  (-j oe)                 #
#    7. email about job abort, begin, end  (-m abe)                #
#    8. email address to use               (-M)                    #
#                                                                  #
#  For more information visit https://docs.exabyte.io/cli/jobs     #
# ---------------------------------------------------------------- #

#PBS -N Si_SIMPLE
#PBS -j oe
##PBS -q comp-002-zone-a-production-20160630-cluster-007.exabyte.io
#PBS -l nodes=1
#PBS -l ppn=4
#PBS -l walltime=00:01:00:00
#PBS -q D
##PBS -m abe
##PBS -M info@exabyte.io
#
## Uncomment the line below and put a desired project name, e.g.:
## "seminar-default" or "john-project"
## NOTE: this is required when using organizational accounts.
## more at https://docs.exabyte.io/jobs-cli/batch-scripts/directives/.
## The job will be charged to the corresponding project.
## When commented out, the default project for user is assumed.
#PBS -A seminar-espresso-tutorials

# load module
module load espresso/7.2-g-11.2.0-ompi-4.1.1-libxc-6.2.0

# go to the job working directory
cd $PBS_O_WORKDIR

# NOTE due to issues with OpenMPI 4.1.1 we currently need to copy
# the PBS_NODEFILE into the .exabyte hidden folder in the WORKDIR
# in order for MPI to be correctly configured.
cp $PBS_NODEFILE .exabyte/$PBS_JOBID

# link input sources
cd output
ln -sf ../input/* .

# run the calculations
mpirun -np $PBS_NP pw.x         -i 01_si_scf_k.in      > 01_si_scf_k.out
mpirun -np $PBS_NP head.x       -i 02_si_head.in       > 02_si_head.out
mpirun -np $PBS_NP pw.x         -i 03_si_nscf.in       > 03_si_nscf.out
mpirun -np $PBS_NP pw4gww.x     -i 04_si_pw4gww.in     > 04_si_pw4gww.out
# `-i filename` may not work with GWW executables, please use std redirection < instead
mpirun -np $PBS_NP gww.x         < 05_si_gww.in        > 05_si_gww.out
mpirun -np $PBS_NP pw.x         -i 06_si_nscf_k.in     > 06_si_nscf_k.out
mpirun -np $PBS_NP simple.x      < 07_si_simple.in     > 07_si_simple.out
mpirun -np $PBS_NP simple_bse.x  < 08_si_simple_bse.in > 08_si_simple_bse.out
# currently, below post processing tool is not installed in mat3ra clusters
# abcoeff_to_eps.x < 09_si_abcoeff_to_eps.in > 09_si_abcoeff_to_eps.tmp
